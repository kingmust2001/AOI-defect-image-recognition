# -*- coding: utf-8 -*-
"""side_Project3_AOI defect.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ic1sgIWuHENDDeRG_hod6lacOjwKn7jQ

## AOI Defect Image recognition

自動光學檢查（Automated Optical Inspection，簡稱 AOI）[1]，為高速高精度光學影像檢測系統，運用機器視覺做為檢測標準技術，可改良傳統上以人力使用光學儀器進行檢測的缺點，應用層面包括從高科技產業之研發、製造品管，以至國防、民生、醫療、環保、電力…等領域。工研院電光所投入軟性電子顯示器之研發多年，在試量產過程中，希望藉由 AOI 技術提升生產品質。本次邀請各界資料科學家共襄盛舉，針對所提供的 AOI 影像資料，來判讀瑕疵的分類，藉以提升透過數據科學來加強 AOI 判讀之效能。

## 評估標準

參與本議題研究者在提供瑕疵預測類別後，系統後台將定期批次處理以計算分數，評估方式採用計算與實際值的相符正確率（Accuracy）。公式如下：
A
c
c
u
r
a
c
y
=
Number of correct predictions/Number of total predictions

### **google drive connect**
"""

#mount google drive
from google.colab import drive
drive.mount("/content/drive")

#change working path
import os
os.chdir("//content/drive/MyDrive/Colab Notebooks/side_Project3_AOI defect /aoi.zip (Unzipped Files)")
os.getcwd()

#confirm GPU device working or not
import tensorflow as tf
tf.config.experimental.list_physical_devices("GPU")

"""### **import data**

"""

import pandas as pd
data_file = "/content/drive/MyDrive/Colab Notebooks/side_Project3_AOI defect /aoi.zip (Unzipped Files)"
training_list = pd.read_csv(os.path.join(data_file, "train.csv"), index_col = False)
training_list

import numpy as np
label, counts = np.unique(training_list.Label.values, return_counts=True)  #five defect category
print(label,"\n",counts)

"""#### **check image** """

import cv2
import matplotlib.pyplot as plt
data_file_image = ("/content/drive/MyDrive/Colab Notebooks/side_Project3_AOI defect /aoi.zip (Unzipped Files)/train_images")
img = cv2.imread(os.path.join(data_file_image, training_list.iloc[0,0]))
print("image shape:", img.shape, "\n", "image data type:", img.dtype, "\n", "image min:", img.min(), "image max:", img.max())
plt.imshow(img)
plt.show()

"""### **classify same category img in to a list**"""

normal_list = training_list[training_list["Label"]==0]["ID"].values
void_list = training_list[training_list["Label"]==1]["ID"].values
horizontal_defect_list = training_list[training_list["Label"]==2]["ID"].values
vertical_defect_list = training_list[training_list["Label"]==3]["ID"].values
edge_defect_list = training_list[training_list["Label"]==4]["ID"].values
particle_list = training_list[training_list["Label"]==5]["ID"].values

label = [normal_list, void_list, horizontal_defect_list, vertical_defect_list, edge_defect_list, particle_list]

"""#### check all category image"""

plt.figure(figsize = (12,6))
for img in range(len(label)):
  plt.subplot(2, 3, img+1)
  defect = cv2.imread(os.path.join(data_file_image, label[img][0]),0)
  plt.imshow(defect)
  plt.title(defect.shape)
  plt.axis("off")
  plt.suptitle("defect category")
plt.show()

plt.figure(figsize = (12,6))
for item in range(len(label)):
  plt.subplot(2,3,item+1)
  defect_hist = cv2.imread(os.path.join(data_file_image, label[item][0]), 0)
  plt.hist(defect_hist.reshape(-1), bins = 50)
  plt.xlabel("pixel value", fontsize=10)
  plt.ylabel("frequency", fontsize = 10)
plt.suptitle("defect image pixel frequency")
plt.show()

"""### implement 值方圖均衡化(Histogram Equalization) and 局部均衡化(createCLAHE) 
#### object:處理影像是偏亮或偏暗

note:createCLAHE，這種方法是對部分影像分別做均衡化，限制局部明暗對比太大的狀況(使用Histogram Equalization是對全局圖片進行調整，因此也會存在著一些問題，像是因為整體影像的亮度增加，可能有些小地方會變得模糊)
"""

#Histogram Equalization
equalize_img = cv2.equalizeHist(defect)

plt.figure(figsize=(12,6))
plt.subplot(2,2,1)
plt.imshow(defect, cmap = "gray")
plt.axis("off")
plt.title("origin")

plt.subplot(2,2,2)
plt.imshow(equalize_img, cmap = "gray")
plt.axis("off")
plt.title("equalize_img")

plt.subplot(2,2,3)
plt.hist(defect_hist.reshape(-1), bins = 50)
plt.title("origin")

plt.subplot(2,2,4)
plt.hist(equalize_img.reshape(-1), bins = 50)
plt.title("equalize_img")
plt.show()

#CreateCLAHE-局部均衡化
clahe = cv2.createCLAHE()
clahe_img = clahe.apply(defect)

plt.figure(figsize=(12,6))
plt.subplot(2,2,1)
plt.imshow(defect, cmap = "gray")
plt.axis("off")
plt.title("origin")

plt.subplot(2,2,2)
plt.imshow(clahe_img, cmap = "gray")
plt.axis("off")
plt.title("clahe_img")

plt.subplot(2,2,3)
plt.hist(defect_hist.reshape(-1), bins = 50)
plt.title("origin")

plt.subplot(2,2,4)
plt.hist(clahe_img.reshape(-1), bins = 50)
plt.title("clahe_img")
plt.show()

"""### **split training data**

#### check training data distribution
"""

import seaborn as sns
print(training_list["Label"].value_counts())
sns.countplot("Label", data = training_list)

from sklearn.model_selection import train_test_split
train, valid = train_test_split(training_list, test_size=0.2,random_state=42)

train.reset_index(drop=True, inplace = True)
valid.reset_index(drop=True, inplace = True)

train["Label"] = train["Label"].astype("str")
valid["Label"] = valid["Label"].astype("str")

print(train.head(10), "\n", "train shape:", train.shape, "\n","valid shape:", valid.shape)

"""#### handle data unbalence by assign weight"""

import numpy as np
label, counts = np.unique(training_list.Label.values, return_counts=True)  #five defect category
print(label,"\n",counts)

from sklearn.utils.class_weight import compute_class_weight
class_weights = compute_class_weight(class_weight ='balanced', classes = np.array(label), y = training_list.Label.values)
print(class_weights)

"""### **import related package**

"""

import tensorflow as tf
from tensorflow import keras 
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import Sequential
from tensorflow.keras.models import Model #Model groups layers into an object with training and inference features.
from tensorflow.keras import models
from tensorflow.keras.layers import Dense
from tensorflow.keras import optimizers
from tensorflow.keras.metrics import categorical_crossentropy
from tensorflow.keras import layers, callbacks
from sklearn.metrics import confusion_matrix
from tensorflow.keras.applications import imagenet_utils

"""### **Data augumentation**"""

train_datagen = ImageDataGenerator(
    rotation_range = 0,
    horizontal_flip = False,
    vertical_flip = False,
    width_shift_range = 0.05,
    height_shift_range = 0.05,
    preprocessing_function = tf.keras.applications.mobilenet.preprocess_input 
) #use mobilenet's preprocessing function -> will compress all values to [0,1] 其他的前處理功能，可自行寫def定義或是使用套件提供的
valid_datagen = ImageDataGenerator(preprocessing_function = tf.keras.applications.mobilenet.preprocess_input)

"""#### apply data augumentation to data

two ways that could apply data augumentation on data

* flow_from_directory: 需要將不同標籤的圖片進行分類，安插在同一個資料夾下
* flow_from_dataframe: 不必將圖片分類，全部放置在一個資料夾即可，但須額為製作一份DataFrame，裡頭要包含圖片的名稱以及標籤
"""

image_shape = (224,224)
batch_size = 16
train_generator = train_datagen.flow_from_dataframe(
    dataframe = train,
    directory = data_file_image,
    x_col = "ID",
    y_col = "Label",
    target_size = image_shape,
    batch_size = batch_size,
    calss_mode = "categorical",
    shuffle = True
)
valid_generator = valid_datagen.flow_from_dataframe(
    dataframe = valid,
    directory = data_file_image,
    x_col = "ID",
    y_col = "Label",
    target_size = image_shape,
    batch_size = batch_size,
    calss_mode = "categorical",
    shuffle = True
)

"""### **application MobileNet model**"""

model = tf.keras.applications.MobileNet(weights = "imagenet", input_shape=(224,224,3), include_top = False)
model.summary()

model.input

x = layers.GlobalAveragePooling2D()(model.output)
outputs = layers.Dense(6, activation = "softmax")(x)
model = Model(inputs = model.input, outputs = outputs)
learning_rate = 0.001
model.compile(
    loss = "categorical_crossentropy",
    metrics = ["accuracy"],
    optimizer = tf.keras.optimizers.Adam(learning_rate)
)

model.summary()

"""### **config model training parameter**

* model_mckp：用來儲存訓練過程中，準確率最高的模型
* earlystop：假如模型一段時間內都沒有進步，那就提前終止模型訓練
"""

# dynamic learning rate
from tensorflow.keras.callbacks import ReduceLROnPlateau
LR_function = ReduceLROnPlateau(
    monitor = "val_acc",
    patience = 5,
    verbose = 1,
    factor = 0.5, # new_lr = lr * factor.
    min_lr = 0.00001
)

#tensorboard
tensorboard_callback = callbacks.TensorBoard(log_dir="./logs")

import os
model_dir = "./model-logs"
if not os.path.exists(model_dir):
  os.makedirs(model_dir)
modelfiles = model_dir + "/{}-best-model.h5".format("B0")
model_mckp = callbacks.ModelCheckpoint(modelfiles, monitor = "val_accuracy", save_best_only=True) #在每一個檢查點(Checkpoint)存檔，下次執行時，就可以從中斷點繼續訓練
earlystop = callbacks.EarlyStopping(monitor = "val_loss", patience=10, verbose=1)
callback_list = [model_mckp, earlystop, LR_function, tensorboard_callback]

"""### **start training**"""

class_weights = {i:value for i, value in enumerate(class_weights)}
class_weights

def num_steps_per_epoch(data_generator, batch_size):
    if data_generator.n % batch_size==0:
        return data_generator.n//batch_size
    else:
        return data_generator.n//batch_size + 1

train_steps = num_steps_per_epoch(train_generator, batch_size)
valid_steps = num_steps_per_epoch(valid_generator, batch_size)

train_steps

tf.config.list_physical_devices("GPU")

history = model.fit_generator(train_generator, steps_per_epoch=train_steps, epochs = 5, validation_data = valid_generator, validation_steps=valid_steps, class_weight = class_weights, callbacks=callback_list)

import matplotlib.pyplot as plt
#print(history.history.keys())
# summarize history for accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left') 
plt.show()

# summarize history for loss 
plt.plot(history.history['loss']) 
plt.plot(history.history['val_loss']) 
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left') 
plt.show()

# Commented out IPython magic to ensure Python compatibility.
#tensorboard
# %load_ext tensorboard
# %tensorboard --logdir logs

"""### **prediction**"""

testing_list = pd.read_csv(os.path.join(data_file, "test.csv"), index_col = False)
testing_list = testing_list[:100]
#testing_list

testing_list.Label = testing_list.Label.astype(str)
testing_list.Label

data_file_image_test = ("/content/drive/MyDrive/Colab Notebooks/side_Project3_AOI defect /aoi.zip (Unzipped Files)/test_images")
test_datagen = ImageDataGenerator(
    preprocessing_function = tf.keras.applications.mobilenet.preprocess_input
)
test_generator = test_datagen.flow_from_dataframe(
    dataframe = testing_list,
    directory = data_file_image_test,
    x_col = "ID",
    y_col = "Label",
    target_size = image_shape,
    batch_size = batch_size,
    class_mode='categorical',
    shuffle = False
)
test_step = num_steps_per_epoch(test_generator, batch_size)

y_pred = model.predict(test_generator, steps = test_step).argmax(-1)
#y_pred = np.argmax(model.predict(valid_generator, steps = valid_steps), axis = 1)
y_pred

"""#### confusion matrix

from sklearn.metrics import accuracy_score, confusion_matrix
import seaborn as sns

print(f"accuracy_score: {accuracy_score(y_test, y_test_pred):.3f}")

confusion = confusion_matrix(y_test, y_test_pred)

plt.figure(figsize=(5, 5))
sns.heatmap(confusion_matrix(y_test, y_test_pred), 
            cmap="Blues", annot=True, fmt="d", cbar=False,
            xticklabels=[0, 1], yticklabels=[0, 1])
plt.title("Confusion Matrix")
plt.show()

## referance
https://ithelp.ithome.com.tw/articles/10263866
"""