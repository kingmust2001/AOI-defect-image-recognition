# -*- coding: utf-8 -*-
"""side_Project3_AOI defect.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ic1sgIWuHENDDeRG_hod6lacOjwKn7jQ

## AOI Defect Image recognition

?ªå??‰å­¸æª¢æŸ¥ï¼ˆAutomated Optical Inspectionï¼Œç°¡ç¨?AOIï¼‰[1]ï¼Œç‚ºé«˜é€Ÿé?ç²¾åº¦?‰å­¸å½±å?æª¢æ¸¬ç³»çµ±ï¼Œé??¨æ??¨è?è¦ºå??ºæª¢æ¸¬æ?æº–æ?è¡“ï??¯æ”¹?¯å‚³çµ±ä?ä»¥äºº?›ä½¿?¨å?å­¸å??¨é€²è?æª¢æ¸¬?„ç¼ºé»ï??‰ç”¨å±¤é¢?…æ‹¬å¾é?ç§‘æ??¢æ¥­ä¹‹ç??¼ã€è£½? å?ç®¡ï?ä»¥è‡³?‹é˜²?æ??Ÿã€é†«?‚ã€ç’°ä¿ã€é›»?›â€¦ç??˜å??‚å·¥?”é™¢?»å??€?•å…¥è»Ÿæ€§é›»å­é¡¯ç¤ºå™¨ä¹‹ç??¼å?å¹´ï??¨è©¦?ç”¢?ç?ä¸­ï?å¸Œæ??‰ç”± AOI ?€è¡“æ??‡ç??¢å?è³ªã€‚æœ¬æ¬¡é?è«‹å??Œè??™ç?å­¸å®¶?±è??›è?ï¼Œé?å°æ??ä???AOI å½±å?è³‡æ?ï¼Œä??¤è??•ç–µ?„å?é¡ï??‰ä»¥?å??é??¸æ?ç§‘å­¸ä¾†å?å¼?AOI ?¤è?ä¹‹æ??½ã€?
## è©•ä¼°æ¨™æ?

?ƒè??¬è­°é¡Œç?ç©¶è€…åœ¨?ä??•ç–µ?æ¸¬é¡åˆ¥å¾Œï?ç³»çµ±å¾Œå°å°‡å??Ÿæ‰¹æ¬¡è??†ä»¥è¨ˆç??†æ•¸ï¼Œè?ä¼°æ–¹å¼æ¡?¨è?ç®—è?å¯¦é??¼ç??¸ç¬¦æ­?¢º?‡ï?Accuracyï¼‰ã€‚å…¬å¼å?ä¸‹ï?
A
c
c
u
r
a
c
y
=
Number of correct predictions/Number of total predictions

### **google drive connect**
"""

#mount google drive
from google.colab import drive
drive.mount("/content/drive")

#change working path
import os
os.chdir("//content/drive/MyDrive/Colab Notebooks/side_Project3_AOI defect /aoi.zip (Unzipped Files)")
os.getcwd()

#confirm GPU device working or not
import tensorflow as tf
tf.config.experimental.list_physical_devices("GPU")

"""### **import data**

"""

import pandas as pd
data_file = "/content/drive/MyDrive/Colab Notebooks/side_Project3_AOI defect /aoi.zip (Unzipped Files)"
training_list = pd.read_csv(os.path.join(data_file, "train.csv"), index_col = False)
training_list

import numpy as np
label, counts = np.unique(training_list.Label.values, return_counts=True)  #five defect category
print(label,"\n",counts)

"""#### **check image** """

import cv2
import matplotlib.pyplot as plt
data_file_image = ("/content/drive/MyDrive/Colab Notebooks/side_Project3_AOI defect /aoi.zip (Unzipped Files)/train_images")
img = cv2.imread(os.path.join(data_file_image, training_list.iloc[0,0]))
print("image shape:", img.shape, "\n", "image data type:", img.dtype, "\n", "image min:", img.min(), "image max:", img.max())
plt.imshow(img)
plt.show()

"""### **classify same category img in to a list**"""

normal_list = training_list[training_list["Label"]==0]["ID"].values
void_list = training_list[training_list["Label"]==1]["ID"].values
horizontal_defect_list = training_list[training_list["Label"]==2]["ID"].values
vertical_defect_list = training_list[training_list["Label"]==3]["ID"].values
edge_defect_list = training_list[training_list["Label"]==4]["ID"].values
particle_list = training_list[training_list["Label"]==5]["ID"].values

label = [normal_list, void_list, horizontal_defect_list, vertical_defect_list, edge_defect_list, particle_list]

"""#### check all category image"""

plt.figure(figsize = (12,6))
for img in range(len(label)):
  plt.subplot(2, 3, img+1)
  defect = cv2.imread(os.path.join(data_file_image, label[img][0]),0)
  plt.imshow(defect)
  plt.title(defect.shape)
  plt.axis("off")
  plt.suptitle("defect category")
plt.show()

plt.figure(figsize = (12,6))
for item in range(len(label)):
  plt.subplot(2,3,item+1)
  defect_hist = cv2.imread(os.path.join(data_file_image, label[item][0]), 0)
  plt.hist(defect_hist.reshape(-1), bins = 50)
  plt.xlabel("pixel value", fontsize=10)
  plt.ylabel("frequency", fontsize = 10)
plt.suptitle("defect image pixel frequency")
plt.show()

"""### implement ?¼æ–¹?–å?è¡¡å?(Histogram Equalization) and å±€?¨å?è¡¡å?(createCLAHE) 
#### object:?•ç?å½±å??¯å?äº®æ??æ?

note:createCLAHEï¼Œé€™ç¨®?¹æ??¯å??¨å?å½±å??†åˆ¥?šå?è¡¡å?ï¼Œé??¶å??¨æ??—å?æ¯”å¤ªå¤§ç??€æ³?ä½¿ç”¨Histogram Equalization?¯å??¨å??–ç??²è?èª¿æ•´ï¼Œå?æ­¤ä??ƒå??¨è?ä¸€äº›å?é¡Œï??æ˜¯? ç‚º?´é?å½±å??„äº®åº¦å?? ï??¯èƒ½?‰ä?å°åœ°?¹æ?è®Šå?æ¨¡ç?)
"""

#Histogram Equalization
equalize_img = cv2.equalizeHist(defect)

plt.figure(figsize=(12,6))
plt.subplot(2,2,1)
plt.imshow(defect, cmap = "gray")
plt.axis("off")
plt.title("origin")

plt.subplot(2,2,2)
plt.imshow(equalize_img, cmap = "gray")
plt.axis("off")
plt.title("equalize_img")

plt.subplot(2,2,3)
plt.hist(defect_hist.reshape(-1), bins = 50)
plt.title("origin")

plt.subplot(2,2,4)
plt.hist(equalize_img.reshape(-1), bins = 50)
plt.title("equalize_img")
plt.show()

#CreateCLAHE-å±€?¨å?è¡¡å?
clahe = cv2.createCLAHE()
clahe_img = clahe.apply(defect)

plt.figure(figsize=(12,6))
plt.subplot(2,2,1)
plt.imshow(defect, cmap = "gray")
plt.axis("off")
plt.title("origin")

plt.subplot(2,2,2)
plt.imshow(clahe_img, cmap = "gray")
plt.axis("off")
plt.title("clahe_img")

plt.subplot(2,2,3)
plt.hist(defect_hist.reshape(-1), bins = 50)
plt.title("origin")

plt.subplot(2,2,4)
plt.hist(clahe_img.reshape(-1), bins = 50)
plt.title("clahe_img")
plt.show()

"""### **split training data**

#### check training data distribution
"""

import seaborn as sns
print(training_list["Label"].value_counts())
sns.countplot("Label", data = training_list)

from sklearn.model_selection import train_test_split
train, valid = train_test_split(training_list, test_size=0.2,random_state=42)

train.reset_index(drop=True, inplace = True)
valid.reset_index(drop=True, inplace = True)

train["Label"] = train["Label"].astype("str")
valid["Label"] = valid["Label"].astype("str")

print(train.head(10), "\n", "train shape:", train.shape, "\n","valid shape:", valid.shape)

"""#### handle data unbalence by assign weight"""

import numpy as np
label, counts = np.unique(training_list.Label.values, return_counts=True)  #five defect category
print(label,"\n",counts)

from sklearn.utils.class_weight import compute_class_weight
class_weights = compute_class_weight(class_weight ='balanced', classes = np.array(label), y = training_list.Label.values)
print(class_weights)

