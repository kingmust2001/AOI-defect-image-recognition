# -*- coding: utf-8 -*-
"""side_Project3_AOI defect.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ic1sgIWuHENDDeRG_hod6lacOjwKn7jQ

import tensorflow as tf
from tensorflow import keras 
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import Sequential
from tensorflow.keras.models import Model #Model groups layers into an object with training and inference features.
from tensorflow.keras import models
from tensorflow.keras.layers import Dense
from tensorflow.keras import optimizers
from tensorflow.keras.metrics import categorical_crossentropy
from tensorflow.keras import layers, callbacks
from sklearn.metrics import confusion_matrix
from tensorflow.keras.applications import imagenet_utils



"""### **application MobileNet model**"""

model = tf.keras.applications.MobileNet(weights = "imagenet", input_shape=(224,224,3), include_top = False)
model.summary()

model.input

x = layers.GlobalAveragePooling2D()(model.output)
outputs = layers.Dense(6, activation = "softmax")(x)
model = Model(inputs = model.input, outputs = outputs)
learning_rate = 0.001
model.compile(
    loss = "categorical_crossentropy",
    metrics = ["accuracy"],
    optimizer = tf.keras.optimizers.Adam(learning_rate)
)

model.summary()

"""### **config model training parameter**

* model_mckp：用來儲存訓練過程中，準確率最高的模型
* earlystop：假如模型一段時間內都沒有進步，那就提前終止模型訓練
"""

# dynamic learning rate
from tensorflow.keras.callbacks import ReduceLROnPlateau
LR_function = ReduceLROnPlateau(
    monitor = "val_acc",
    patience = 5,
    verbose = 1,
    factor = 0.5, # new_lr = lr * factor.
    min_lr = 0.00001
)

#tensorboard
tensorboard_callback = callbacks.TensorBoard(log_dir="./logs")

import os
model_dir = "./model-logs"
if not os.path.exists(model_dir):
  os.makedirs(model_dir)
modelfiles = model_dir + "/{}-best-model.h5".format("B0")
model_mckp = callbacks.ModelCheckpoint(modelfiles, monitor = "val_accuracy", save_best_only=True) #在每一個檢查點(Checkpoint)存檔，下次執行時，就可以從中斷點繼續訓練
earlystop = callbacks.EarlyStopping(monitor = "val_loss", patience=10, verbose=1)
callback_list = [model_mckp, earlystop, LR_function, tensorboard_callback]

